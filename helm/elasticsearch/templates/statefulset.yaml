apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ include "elasticsearch.fullname" . }}
  labels:
    app.kubernetes.io/name: {{ include "elasticsearch.name" . }}
    helm.sh/chart: {{ include "elasticsearch.chart" . }}
    app.kubernetes.io/instance: {{ .Release.Name }}
    app.kubernetes.io/managed-by: {{ .Release.Service }}
spec:
  replicas: {{ .Values.replicaCount }}
  serviceName: {{ include "elasticsearch.fullname" . }}-transport
  podManagementPolicy: Parallel
  selector:
    matchLabels:
      app.kubernetes.io/name: {{ include "elasticsearch.name" . }}
      app.kubernetes.io/instance: {{ .Release.Name }}
  template:
    metadata:
      labels:
        app.kubernetes.io/name: {{ include "elasticsearch.name" . }}
        app.kubernetes.io/instance: {{ .Release.Name }}
    spec:
      securityContext:
        fsGroup: 102
      initContainers:
        - name: init-sysctl
          image: busybox:1
          command: ["sysctl", "-w", "vm.max_map_count=262144"]
          securityContext:
            privileged: true
        - name: init-volume
          image: busybox:1
          command: ["chgrp", "-v", "102", "/data" ]
          # we had previously been using the following command for local dev
          # keeping this commented until we determine it wasn't for any particular reason
          # and confirm both the chgrp command above and this one perform the same effective fxn
          # or find out that the chown command is preferred, etc...
          # command: ["chown", "-v", "1000:1000", "/data" ]
          volumeMounts:
            - name: data
              mountPath: "/data"
      containers:
        - name: {{ .Chart.Name }}
          image: {{ printf "%s:%s" .Values.image.repository .Values.image.tag | quote }}
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          ports:
            - name: http
              containerPort: {{ .Values.service.port }}
              protocol: TCP
            - name: transport
              containerPort: {{ .Values.service.portTransport }}
              protocol: TCP
          volumeMounts:
            - name: data
              mountPath: "/usr/share/elasticsearch/data"
          env:
            - name: cluster.name
              value: {{ .Values.cluster.name }}
            - name: discovery.zen.ping.unicast.hosts
              value: {{ include "elasticsearch.fullname" . }}-transport
            - name: discovery.zen.minimum_master_nodes
              value: "{{ div .Values.replicaCount 2 | add1 }}"
            - name: ES_JAVA_OPTS
              value: "-Xms{{ .Values.cluster.heapMi }}m -Xmx{{ .Values.cluster.heapMi }}m"
            # TODO - lock the memory
            - name: xpack.security.enabled
              value: "{{ .Values.cluster.xpackEnabled }}"
            - name: xpack.watcher.enabled
              value: "{{ .Values.cluster.xpackEnabled }}"
            - name: xpack.monitoring.enabled
              value: "{{ .Values.cluster.xpackEnabled }}"
            - name: xpack.ml.enabled
              value: "{{ .Values.cluster.xpackEnabled }}"
            - name: xpack.graph.enabled
              value: "{{ .Values.cluster.xpackEnabled }}"
            {{- range $key, $value :=  .Values.cluster.env }}
            - name: {{ $key }}
              value: {{ $value | quote }}
            {{- end }}
          livenessProbe:
            httpGet:
              path: /
              port: http
            initialDelaySeconds: 30
          resources:
            limits:
              cpu: {{ .Values.cluster.cpu }}
              memory: {{ mul 2 .Values.cluster.heapMi }}Mi
            requests:
              cpu: {{ .Values.cluster.cpu }}
              memory: {{ .Values.cluster.heapMi }}Mi
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: "app"
                  operator: In
                  values:
                  - {{ include "elasticsearch.name" . }}
              topologyKey: "kubernetes.io/hostname"
    {{- with .Values.nodeSelector }}
      nodeSelector:
{{- toYaml . | nindent 8 }}
    {{- end }}

    {{- with .Values.tolerations }}
      tolerations:
{{- toYaml . | nindent 8 }}
    {{- end }}
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes:
      - ReadWriteOnce
{{- if .Values.cluster.storageClass }}
      storageClassName: {{ .Values.cluster.storageClass }}
{{- end }}
      resources:
        requests:
          storage: {{ .Values.cluster.diskGi }}Gi